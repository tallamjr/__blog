---
author: Tarek Allam
categories:
- tutorials
image: img/posts/2017-12-06-Metrics/metric.png
date: "2017-12-06T00:00:00Z"
draft: false
tags:
- programming
- unix
- cloud
title: Models and Metrics in Classification
---

*This is a brief overview of Classification models and how metrics are used.*

<!--more-->

<img src="https://imgs.xkcd.com/comics/machine_learning.png"
style="float: right;margin: 0px 0px 10px 15px;">

Open challenges have become a popular and effective route to promoting the
development of novel techniques in astronomical data analysis. However, the
probabilistic data products appropriate to upcoming deep surveys are incompatible
with the traditional metrics used on deterministic classifications.
Furthermore, large survey collaborations such as the Large Synoptic Survey
Telescope (LSST) may use the products of these challenges for diverse science
objectives, indicating a need for a metric that balances a variety of goals. We
describe the process used to develop an appropriate global performance metric
for a challenge affected by both these issues in the context of the Photometric
LSST Astronomical Time-series Classification Challenge (PLAsTiCC), a
[Kaggle](https://www.kaggle.com/)
competition aiming to identify promising methods for obtaining classification
probabilities of transient and variable objects by engaging the broader
community outside astronomy. We suggest some guiding principles for approaching
the choice of a metric of probabilistic classifications and propose extensions
of our procedure to ever more complex challenges.

# Table of contents

1. [Introduction to PLAsTiCC](#introduction)
2. [Log-Loss](#logloss)
3. [Brier Score](#brier)

<a name="introduction"></a>
## The Photometric LSST Astronomical Time-series Classification Challenge (PLAsTiCC)
