<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.69.2" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark">

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>


<script async defer src="https://buttons.github.io/buttons.js"></script>



<link rel="icon" href="https://lh3.googleusercontent.com/proxy/XQN2qZ7OfPdQDKr5E70HlXfIYolqvsb2YANAoe_ACDdVYqzaPDje7vCpbBCaoz0DjPLuEyUl7Ry_EXWi9SKCDWZt08gJLSedRLIIZn4CYE-HEdLCPhQEF2OcENQCaA33">


<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

<style>
.tooltip {
  display: inline;
  position: relative;
  border-bottom: 2px dotted black;
}

.tooltip:hover {
  color: #fc6a5d;
  text-decoration: none;
}

.tooltip:hover:after {
  background: #111;
  background: rgba(0, 0, 0, .8);
  border-radius: 1em;
  color: #fff;
  content: attr(title);
  display: block;
  padding: .3em 1em;
  position: absolute;
  text-shadow: 0 1px 0 #000;
  word-wrap: break-word;
  min-width: 600px;
  max-width: 100%;
  z-index: 100;
}

.tooltip-right:hover:after {
  background: #111;
  background: rgba(0, 0, 0, .8);
  border-radius: 1em;
  color: #fff;
  content: attr(title);
  display: block;
  bottom: 1em;
  right: 1em;
  padding: .3em 1em;
  position: absolute;
  text-shadow: 0 1px 0 #000;
  word-wrap: break-word;
  min-width: 600px;
  max-width: 100%;
  z-index: 100;
}

.tooltip-left:hover:after {
  background: #111;
  background: rgba(0, 0, 0, .8);
  border-radius: 1em;
  color: #fff;
  content: attr(title);
  display: block;
  bottom: 1em;
  left: 1em;
  padding: .3em 1em;
  position: absolute;
  text-shadow: 0 1px 0 #000;
  word-wrap: break-word;
  min-width: 600px;
  max-width: 100%;
  z-index: 100;
}

.tooltip:hover:before {
  border: solid;
  border-color: #111 transparent;
  border-color: rgba(0, 0, 0, .8) transparent;
  border-width: .4em .4em 0 .4em;
  bottom: 1em;
  content: "";
  display: block;
  left: 2em;
  position: absolute;
  z-index: 100;
}

</style><title>Using PySpark to call compiled Scala from Python&nbsp;&ndash;&nbsp;The AstroInformatic</title><link rel="stylesheet" href="/blog/css/core.min.272cb8d2c49ee6175e4c3f7f89fb6a0cb80e0dd5ce88107183aa6cf7e4a2b2411c914fab7aba413197d249cda3815434.css" integrity="sha384-Jyy40sSe5hdeTD9/iftqDLgODdXOiBBxg6ps9&#43;SiskEckU&#43;rerpBMZfSSc2jgVQ0"><body>
    <div class="base-body"><section id="header" class="site header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/blog/"><span class="site name">The AstroInformatic</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/blog/about/">About</a><a class="nav item" href="/blog/contact/">Contact</a><a class="nav item" href="/blog/projects/">Projects</a><a class="nav item" href="/blog/categories/">Categories</a><a class="nav item" href="/blog/tags/">Tags</a></nav></div></span></div><div class="site slogan"><span class="title">#astroinformatics</span></div></section><div id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">Using PySpark to call compiled Scala from Python</h1><p class="article date">May 20, 2020<span class="reading-time"> • 3 minutes to read</span></p></section><article class="article markdown-body"><p>Calling compiled Scala code inside the JVM from Python using PySpark</p>
<p>There is no doubt that Java and Scala are the de-facto languages for Data Engineering, whilst Python
is certainly the front runner for language of choice with Data Scientists. Spark; a framework for
distributed data analytics is written in Scala but allows for usage in Python, R and Java.
Interoperability between Java and Scala is a no briner since Scala compiles down to Java byte code,
but call Scala from Python is a little more involved, but the process is very simple.</p>
<p>The code used in this post builds upon the code used in a previous post and has the standard maven
directory layout. We will be calling <code>simple.SimpleApp.hello()</code> function to print <code>&quot;Hello, World!&quot;</code>.</p>
<p>The simple Scala we will use is the following:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">$ cat -n src/main/scala/simple/SimpleApp.scala

 1	package simple<span class="p">;</span>
 <span class="m">2</span>
 3	object SimpleApp <span class="o">{</span>
 4	  def hello<span class="o">()</span>: <span class="nv">Unit</span> <span class="o">=</span> <span class="o">{</span>
 5	    println<span class="o">(</span><span class="s2">&#34;Hello, Wolrd&#34;</span><span class="o">)</span>
 6	  <span class="o">}</span>
 7	<span class="o">}</span>

</code></pre></div><p>This will then be compiled and packaged using <code>sbt</code> to created a <code>.jar</code> file that can be included in
the running JVM instance when launching Spark. Thus, after running:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">$ sbt clean compile package

<span class="o">[</span>info<span class="o">]</span> Loading settings <span class="k">for</span> project simpleapp-build from plugins.sbt ...
<span class="o">[</span>info<span class="o">]</span> Loading project definition from /Users/tallamjr/www/blog/code/posts/2020-05-20-Scala-Python-JVM/simpleApp/project
<span class="o">[</span>info<span class="o">]</span> Loading settings <span class="k">for</span> project simpleapp from build.sbt ...
<span class="o">[</span>info<span class="o">]</span> Set current project to SimpleApp <span class="o">(</span>in build file:/Users/tallamjr/www/blog/code/posts/2020-05-20-Scala-Python-JVM/simpleApp/<span class="o">)</span>
<span class="o">[</span>info<span class="o">]</span> Executing in batch mode. For better performance use sbt<span class="err">&#39;</span>s shell
<span class="o">[</span>success<span class="o">]</span> Total time: <span class="m">0</span> s, completed 21-May-2020 13:18:19
<span class="o">[</span>info<span class="o">]</span> Compiling <span class="m">1</span> Scala <span class="nb">source</span> to /Users/tallamjr/www/blog/code/posts/2020-05-20-Scala-Python-JVM/simpleApp/target/scala-2.12/classes ...
<span class="o">[</span>success<span class="o">]</span> Total time: <span class="m">7</span> s, completed 21-May-2020 13:18:25
<span class="o">[</span>success<span class="o">]</span> Total time: <span class="m">0</span> s, completed 21-May-2020 13:18:26

</code></pre></div><p>We obtain <code>target/scala-2.12/simpleapp_2.12-1.0.jar</code> which is supplied to Spark like so:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">$ spark-submit --driver-class-path target/scala-2.12/simpleapp_2.12-1.0.jar simpleSpark/main.py

</code></pre></div><p><code>simpleSpark/main.py</code> is the where the <code>pyspark</code> code lives that will be calling the Scala function,
let&rsquo;s have a look into that file:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span> \
    <span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&#34;local[*]&#34;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&#34;simpleSpark&#34;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>
<span class="n">sc</span><span class="o">.</span><span class="n">setLogLevel</span><span class="p">(</span><span class="s2">&#34;ERROR&#34;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">logLevel</span><span class="p">(</span><span class="n">sc</span><span class="p">):</span>
    <span class="c1"># REF: https://stackoverflow.com/questions/25193488/how-to-turn-off-info-logging-in-spark</span>
    <span class="n">log4jLogger</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">log4j</span>
    <span class="n">log4jLogger</span><span class="o">.</span><span class="n">Logger</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&#34;org&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">log4jLogger</span><span class="o">.</span><span class="n">Level</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
    <span class="n">log</span> <span class="o">=</span> <span class="n">log4jLogger</span><span class="o">.</span><span class="n">LogManager</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="n">log</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&#34;Custom WARN message&#34;</span><span class="p">)</span>


<span class="n">logLevel</span><span class="p">(</span><span class="n">spark</span><span class="p">)</span>


<span class="k">print</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="s2">&#34;id &gt; 500&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&#34;sum(id)&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">())</span>

<span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">simple</span><span class="o">.</span><span class="n">SimpleApp</span><span class="o">.</span><span class="n">hello</span><span class="p">()</span>

</code></pre></div><p>There is a bit of boilerplate to get the session started and some customisation with logging going
on but the key lines of code are:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">...</span>
 <span class="mi">8</span>  <span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>
<span class="o">...</span>
<span class="mi">25</span>  <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">simple</span><span class="o">.</span><span class="n">SimpleApp</span><span class="o">.</span><span class="n">hello</span><span class="p">()</span>
</code></pre></div><p>The resulting output after running <code>spark-submit</code> is:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">$ spark-submit --driver-class-path target/scala-2.12/simpleapp_2.12-1.0.jar simpleSpark/main.py

20/05/21 13:26:02 WARN Utils: Your hostname, Tareks-MacBook-Pro.local resolves to a loopback address: 127.0.0.1<span class="p">;</span> using 192.168.0.178 instead <span class="o">(</span>on interface en0<span class="o">)</span>
20/05/21 13:26:02 WARN Utils: Set SPARK_LOCAL_IP <span class="k">if</span> you need to <span class="nb">bind</span> to another address
20/05/21 13:26:02 WARN NativeCodeLoader: Unable to load native-hadoop library <span class="k">for</span> your platform... using builtin-java classes where applicable
<span class="o">[</span>Row<span class="o">(</span>sum<span class="o">(</span>id<span class="o">)=</span>12372250<span class="o">)]</span>
Hello, Wolrd!
</code></pre></div><h1 id="references">References</h1>
<p>This post was inspired by Alexis Seigneurin&rsquo;s much more detailed post <a href="https://aseigneurin.github.io/2016/09/01/spark-calling-scala-code-from-pyspark.html"target="_blank">Spark - Calling Scala code from PySpark</a> which I highly recommend reading.</p></article><section class="article labels"><a class="tag" href=/blog/tags/reproducibility/>reproducibility</a><a class="tag" href=/blog/tags/programming/>programming</a></section></div><section class="article navigation"><p><a class="link" href="/blog/posts/2020-05-27-awesome-blogs/"><span class="li">&larr;</span>Awesome Engineering Blogs</a></p><p><a class="link" href="/blog/posts/2020-05-18-bufdo-will-do/"><span class="li">&rarr;</span>Ah bufdo; That'll do..</a></p></section></div>
    <script src="https://utteranc.es/client.js"
            repo="tallamjr/blog"
            issue-term="pathname"
            label="comments"
            theme="github-dark-orange"
            crossorigin="anonymous"
            async>
    </script><section id="footer" class="footer"><div class="footer-wrap">
    <p class="copyright">©2020 Notepadium.</p>
    <p class="powerby"><span>Powered by </span><a href="https://gohugo.io" 
        target="_blank">Hugo</a><span> and the </span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank">Notepadium</a></p>
</div></section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-163920785-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
</div>
</body>

</html>